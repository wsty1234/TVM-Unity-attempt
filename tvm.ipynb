{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from tvm.contrib.download import download_testdata\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tvm import relax,relay,auto_scheduler\n",
    "from tvm.script import tir as T\n",
    "from tvm.script import relax as R   \n",
    "import tvm\n",
    "from tvm.contrib import graph_executor\n",
    "from tvm.relax.testing import from_relay\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"resnet18\"\n",
    "model = getattr(torchvision.models, model_name)(pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# We grab the TorchScripted model via tracing\n",
    "input_shape = [1, 3, 224, 224]\n",
    "input_data = torch.randn(input_shape)\n",
    "scripted_model = torch.jit.trace(model, input_data).eval()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "img_url = \"https://github.com/dmlc/mxnet.js/blob/main/data/cat.png?raw=true\"\n",
    "img_path = download_testdata(img_url, \"cat.png\", module=\"data\")\n",
    "print(img_path)\n",
    "img = Image.open(img_path).resize((224, 224))\n",
    "\n",
    "# Preprocess the image and convert to tensor\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "my_preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "img = my_preprocess(img)\n",
    "img = np.expand_dims(img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relax.frontend.torch import from_fx\n",
    "from tvm import meta_schedule as ms\n",
    "\n",
    "input_info = [(img.shape, \"float32\")]\n",
    "with torch.no_grad():\n",
    "    fx_module = fx.symbolic_trace(model)\n",
    "    mod_from_torch = from_fx(fx_module, input_info, keep_params_as_input=True)\n",
    "\n",
    "mod_from_torch, params_from_torch = relax.frontend.detach_params(mod_from_torch)\n",
    "mod = relax.transform.LegalizeOps()(mod_from_torch)\n",
    "mod = relax.get_pipeline()(mod_from_torch)\n",
    "\n",
    "l = list(mod.get_global_vars())\n",
    "mod_list =[]\n",
    "for i in range(len(l)):\n",
    "    mod_list.append(str(mod.get_global_vars()[i]))\n",
    "mod_list = list(map(lambda x : x.split('\"')[-2], mod_list))\n",
    "mod_list.remove(\"main\")\n",
    "\n",
    "nd_params = {k : tvm.nd.array(v.detach().numpy()) for k,v in model.named_parameters()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tvm.target.Target(\"llvm --num-cores=8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = ms.tune_tir(\n",
    "        mod=mod,\n",
    "        target=\"llvm --num-cores=8\",\n",
    "        max_trials_global=600,\n",
    "        num_trials_per_iter=10,\n",
    "        work_dir=\"./tune_tmp\",\n",
    "        runner = ms.runner.LocalRunner(\n",
    "          evaluator_config=ms.runner.EvaluatorConfig(),\n",
    "          alloc_repeat=1,\n",
    "        ),\n",
    "        cost_model=ms.cost_model.XGBModel(  \n",
    "                extractor=ms.feature_extractor.PerStoreFeature(),\n",
    "                adaptive_training=True,\n",
    "        ),\n",
    "        strategy=ms.search_strategy.EvolutionarySearch(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyMod2 = relax.transform.BindParams(\"main\", nd_params)(mod)\n",
    "for i in range(len(mod_list)):\n",
    "    mod_str = mod_list[i]\n",
    "    sch = ms.tir_integration.compile_tir(database, mod[mod_str], \"llvm --num-cores=8\")\n",
    "    if(sch == None):\n",
    "        print(1)\n",
    "        continue\n",
    "    new_func = sch.mod[\"main\"].with_attr(\"global_symbol\", mod_str)\n",
    "    gv = MyMod2.get_global_var(mod_str)\n",
    "    MyMod2.update_func(gv, new_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nd = np.random.rand(1,3,244,244)\n",
    "data_nd = data_nd.astype(np.float32)\n",
    "data_nd = tvm.nd.array(data_nd)\n",
    "\n",
    "dev = tvm.device(\"llvm  --num-cores=8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = relax.build(MyMod2, target=\"llvm  --num-cores=8\")\n",
    "vm = relax.VirtualMachine(ex, dev)\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithParams2 Prediction:\",pred_kind)\n",
    "\n",
    "ftimer = vm.module.time_evaluator(\"main\", dev, number=10)\n",
    "print(\"MyModuleWithParams time-cost: %g ms\" % (ftimer(data_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU VERSION DOWN relax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tvm.target.Target(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import dlight as dl\n",
    "\n",
    "with tvm.target.Target(\"cuda\"):\n",
    "    gpu_mod = dl.ApplyDefaultSchedule(\n",
    "    )(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_my_tir(mod_str, max_trials_global,num_trials_per_iter,min_repeat_ms):\n",
    "    if (min_repeat_ms > 1000):\n",
    "        min_repeat_ms = 1000\n",
    "    database = ms.tune_tir(\n",
    "        mod=gpu_mod[mod_str],\n",
    "        target=\"nvidia/geforce-rtx-4090\",\n",
    "        max_trials_global=max_trials_global,\n",
    "        num_trials_per_iter=num_trials_per_iter,\n",
    "        work_dir=\"./tune_tmp\",\n",
    "        runner = ms.runner.LocalRunner(\n",
    "          evaluator_config=ms.runner.EvaluatorConfig(\n",
    "            number=10,\n",
    "            repeat=1,\n",
    "            min_repeat_ms=min_repeat_ms,\n",
    "          ),\n",
    "          alloc_repeat=1,\n",
    "        ),\n",
    "        cost_model=ms.cost_model.XGBModel(  \n",
    "                extractor=ms.feature_extractor.PerStoreFeature(),\n",
    "                adaptive_training=True,\n",
    "        ),\n",
    "        strategy=ms.search_strategy.EvolutionarySearch(),\n",
    "    )\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MyModgpu = relax.transform.BindParams(\"main\", nd_params)(gpu_mod)\n",
    "for i in range(len(mod_list)):\n",
    "    max_trials_global = 64\n",
    "    num_trials_per_iter = 64\n",
    "    min_repeat_ms = 200\n",
    "    mod_str = mod_list[i]\n",
    "    print(mod_str)\n",
    "    database = tune_my_tir(mod_str, max_trials_global,num_trials_per_iter,min_repeat_ms)\n",
    "    sch = ms.tir_integration.compile_tir(database, gpu_mod[mod_str], \"nvidia/geforce-rtx-4090\")\n",
    "    while( sch is None):\n",
    "       print(\"retune begin ................\")\n",
    "       max_trials_global = max_trials_global * 2\n",
    "       num_trials_per_iter = num_trials_per_iter * 2\n",
    "       min_repeat_ms = int(min_repeat_ms * 1.25)\n",
    "       database = tune_my_tir(mod_str, max_trials_global,num_trials_per_iter,min_repeat_ms) \n",
    "       sch = ms.tir_integration.compile_tir(database, gpu_mod[mod_str], \"nvidia/geforce-rtx-4090\")\n",
    "       if(max_trials_global > 10000):\n",
    "           break\n",
    "    new_func = sch.mod[\"main\"].with_attr(\"global_symbol\", mod_str)\n",
    "    gv = MyModgpu.get_global_var(mod_str)\n",
    "    MyModgpu.update_func(gv, new_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = tvm.device('cuda',0)\n",
    "data_nd = tvm.nd.array(img, dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec = relax.build(MyModgpu, target=\"cuda\")\n",
    "vm = relax.VirtualMachine(exec, dev)\n",
    "\n",
    "nd_res = vm[\"main\"](data_nd)\n",
    "\n",
    "pred_kind = np.argmax(nd_res.numpy(), axis=1)\n",
    "print(\"MyModuleWithGPU Prediction:\",pred_kind)\n",
    "\n",
    "ftimer = vm.module.time_evaluator(\"main\", dev, number=1000)\n",
    "print(\"MyModuleWithParams time-cost: %g ms\" % (ftimer(data_nd).mean * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIRST WE USE RELAY DO SOMETHING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_info = [('input1', img.shape)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, params = relay.frontend.from_pytorch(scripted_model, input_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=tvm.target.Target(\"cuda\")\n",
    "dtype=\"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, task_weights = auto_scheduler.extract_tasks(mod[\"main\"], params=params, target=target, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tuning():\n",
    "  print(\"Begin Tunning....\")\n",
    "  measure_ctx = auto_scheduler.LocalRPCMeasureContext(repeat=1, min_repeat_ms=300, timeout=10)\n",
    "  tuner = auto_scheduler.TaskScheduler(tasks, task_weights)\n",
    "  tune_option = auto_scheduler.TuningOptions(\n",
    "        num_measure_trials=200,  # change this to 20000 to achieve the best performance\n",
    "        runner=measure_ctx.runner,\n",
    "        measure_callbacks=[auto_scheduler.RecordToFile(log_file)],\n",
    "    )\n",
    "\n",
    "  tuner.tune(tune_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"try_to_tune_1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib import graph_executor\n",
    "\n",
    "print(\"Compile...\")\n",
    "with auto_scheduler.ApplyHistoryBest(log_file):\n",
    "    with tvm.transform.PassContext(opt_level=3, config={\"relay.backend.use_auto_scheduler\": True}):\n",
    "        lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "# Create graph executor\n",
    "dev = tvm.device(str(target), 0)\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))\n",
    "data_tvm = tvm.nd.array((np.random.uniform(size=img.shape)).astype(dtype))\n",
    "module.set_input(\"input1\", data_tvm)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Evaluate inference time cost...\")\n",
    "print(module.benchmark(dev, repeat=3, min_repeat_ms=500))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
